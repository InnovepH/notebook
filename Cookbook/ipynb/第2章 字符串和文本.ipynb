{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 针对任意多的分隔符拆分字符串\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们需要将字符串拆分为不同的字段，但是分隔符（以及分隔符之间的空格）在整个字符串中并不一致\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "字符串对象的 split() 方法只能处理非常简单的情况，而且不支持多个分隔符，对分隔符周围存在的空格也无能为力\n",
    "\n",
    "所以应该使用 re.split() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "line = 'asdf fjdk; afed, fjek,asdf,    foo'\n",
    "re.split(r'[;,\\s]\\s*', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "如果用到了捕获组，那么匹配的文本也会包含在最终结果中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n",
      "[' ', ';', ',', ',', ',', '']\n"
     ]
    }
   ],
   "source": [
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']\n",
    "print(values)\n",
    "print(delimiters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf fjdk;afed,fjek,asdf,foo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reform the line using the same delimiters\n",
    "''.join(v + d for v, d in zip(values, delimiters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想在结果中看到分隔字符，但仍然想用括号来对正则表达式模式进行分组，请确保用的是非捕获组\n",
    "\n",
    "以 (?:...) 的形式指定，详情看 [正则表达式学习参考](https://blog.csdn.net/lxcnn/article/details/4268033)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 在字符串的开头或结尾处做文本匹配\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们需要在字符串的开头或结尾处按照指定的文本模式做检查，例如检查文件的拓展名，URL协议类型等\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "str.startswith() 和 str.endswith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chrome快捷键.jpg',\n",
       " 'Data Analysis.txt',\n",
       " 'Git.txt',\n",
       " 'keyboard-VSCode-windows.pdf',\n",
       " 'linux.txt',\n",
       " 'linux常用命令.pdf',\n",
       " 'Python.txt',\n",
       " 'sublime text.txt',\n",
       " 'vi-vim-cheat-sheet-sch.gif',\n",
       " 'web.txt',\n",
       " 'windows.txt',\n",
       " '手机号解绑.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filenames = os.listdir(r'C:\\Users\\Ph\\Desktop\\log')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keyboard-VSCode-windows.pdf', 'linux常用命令.pdf', 'vi-vim-cheat-sheet-sch.gif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in filenames if name.endswith(('.pdf', '.gif'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(name.endswith('.jpg') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = ['http:', 'ftp:']\n",
    "url = 'http://www.python.org'\n",
    "url.startswith(tuple(choices))  # 需要先用 tuple() 转换成元组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 利用 Shell 通配符做字符串匹配\n",
    "\n",
    "### 问题\n",
    "\n",
    "当工作在 UNIX Shell 下时，我们想使用常见的通配符模式来对文本做匹配\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "fnmatch 模块提供了两个函数 —— fnmatch() 和 fnmatchcase() —— 可用来执行这样的匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Dat1.csv', 'Dat2.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "print(fnmatch('foo.txt', '*.txt'))\n",
    "print(fnmatch('foo.txt', '?oo.txt'))\n",
    "print(fnmatch('Dat45.csv', 'Dat[0-9]*'))\n",
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']\n",
    "[name for name in names if fnmatch(name, 'Dat*.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(fnmatch('foo.txt', '*.TXT'))\n",
    "print(fnmatchcase('foo.txt', '*.TXT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST']\n",
      "['1060 W ADDISON ST', '1039 W GRANVILLE AVE']\n"
     ]
    }
   ],
   "source": [
    "addresses = [\n",
    "    '5412 N CLARK ST',\n",
    "    '1060 W ADDISON ST',\n",
    "    '1039 W GRANVILLE AVE',\n",
    "    '2122 N CLARK ST',\n",
    "    '4802 N BROADWAY',\n",
    "]\n",
    "print([addr for addr in addresses if fnmatchcase(addr, '* ST')])\n",
    "print([addr for addr in addresses if fnmatchcase(addr, '10[0-9][0-9] W *')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "如果只是试着在处理数据时提供一种简单的机制以允许使用通配符，那么通常这都是个合理的解决方案\n",
    "\n",
    "如果实际上是想编写匹配文件名的代码，那应该使用 glob 模块来完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 文本模式的匹配和查找\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想要按照特定的文本模式进行匹配或查找\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "如果想要匹配的只是简单的文字，那么通常只需要用基本的字符串方法\n",
    "\n",
    "如 str.find()、str.endswith()、str.startswith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "\n",
    "# Exact match\n",
    "print(text == 'yeah')\n",
    "\n",
    "# Match at start or end\n",
    "print(text.startswith('yeah'))\n",
    "print(text.endswith('no'))\n",
    "\n",
    "# Search for the location of the first occurrence\n",
    "print(text.find('no'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text1 = '11/27/2012'\n",
    "text2 = 'Nov 27, 2012'\n",
    "\n",
    "# Simple matching: \\d+ means match one or more digits\n",
    "if re.match(r'\\d+/\\d+/\\d+', text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "if re.match(r'\\d+/\\d+/\\d+', text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "if datepat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "if datepat.match(text2):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match() 方法总是尝试在字符串的开头找到匹配项。如果想针对整个文本搜索出所有的匹配项，那么就应该使用findall()方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3/20/2019', '3/13/2013']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is 3/20/2019. PyCon Starts 3/13/2013'\n",
    "datepat.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入捕获组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='11/27/2012'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "m = datepat.match(text1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/27/2012\n",
      "11\n",
      "27\n",
      "2012\n",
      "('11', '27', '2012')\n"
     ]
    }
   ],
   "source": [
    "print(m.group(0))\n",
    "print(m.group(1))\n",
    "print(m.group(2))\n",
    "print(m.group(3))\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', '20', '2019'), ('3', '13', '2013')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datepat.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-3-20\n",
      "2013-3-13\n"
     ]
    }
   ],
   "source": [
    "for month, day, year in datepat.findall(text):\n",
    "    print(f'{year}-{month}-{day}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 查找和替换文本\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想对字符串中的文本做查找和替换\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "对于简单的文本模式，使用 str.replace() 即可\n",
    "针对更为复杂的模式，可以使用 re 模块中的 sub() 函数/方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yep, but no, but yep, but no, but yep'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text.replace('yeah', 'yep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2019-3-24. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = 'Today is 3/24/2019. PyCon starts 3/13/2013.'\n",
    "re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果打算用相同的模式执行重复替换，可以考虑先将模式编译以获得更好的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2019-3-24. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "datepat.sub(r'\\3-\\1-\\2', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于更复杂的情况，可以指定一个替换回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 24 Mar 2019. PyCon starts 13 Mar 2013.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calendar import month_abbr\n",
    "\n",
    "\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "\n",
    "\n",
    "datepat.sub(change_date, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换回调函数的输入参数是一个匹配对象，由 match() 或 find() 返回。用 .group() 方法来提取匹配中特定的部分。这个函数应该返回替换后的文本\n",
    "\n",
    "除了得到替换后的文本外，如果还想知道一共完成了多少次替换，可以使用 re.subn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2019-3-24. PyCon starts 2013-3-13.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "newtext, n = datepat.subn(r'\\3-\\1-\\2', text)\n",
    "print(newtext)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 以不区分大小写的方式对文本做查找和替换\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们需要以不区分大小写的方式在文本中进行查找，可能还需要做替换\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "使用 re 模块并且对各种操作都加上 re.IGNORECASE 标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PYTHON', 'python', 'Python']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "re.findall('python', text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER snake, lower snake, Mixed snake'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('python', 'snake', text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这个例子揭示出了一种局限，待替换的文本与匹配的文本大小并不吻合\n",
    "\n",
    "如果想要修正这个问题，需要用到一个支撑函数 ( support function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER SNAKE, lower snake, Mixed Snake'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matchcase(word):\n",
    "    def replace(m):\n",
    "        text = m.group()\n",
    "        if text.isupper():\n",
    "            return word.upper()\n",
    "        elif text.islower():\n",
    "            return word.lower()\n",
    "        elif text[0].isupper():\n",
    "            return word.capitalize()\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    return replace\n",
    "\n",
    "\n",
    "re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 定义实现最短匹配的正则表达式\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们正在尝试正则表达式对文本模式做匹配，但识别出来的是最长的可能匹配。相反，我们想将其修改为找出最短的可能匹配\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "在模式中的 * 操作符后加上 ? 修饰符以进行非贪婪模式匹配\n",
    "\n",
    "详情可参考专业正则教程：[正则基础](https://blog.csdn.net/lxcnn/article/category/538256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
    "text1 = 'Computer says \"no.\"'\n",
    "str_pat.findall(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.\" Phone says \"yes.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.', 'yes.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_patt = re.compile(r'\\\"(.*?)\\\"')\n",
    "str_patt.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 编写多行模式的正则表达式\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们打算用正则表达式对一段文本块做匹配，但是希望在进行匹配时能够跨越多行\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "我们希望使用句点 (.) 来匹配任意字符，但是句点并不能匹配换行符。要解决这个问题，可以添加对换行符的支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' this is a comment ']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a \n",
    "              multiline comment */\n",
    "        '''\n",
    "print(comment.findall(text1))\n",
    "print(comment.findall(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a \\n              multiline comment ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模式中，(?:.|\\n) 指定了一个非捕获组（即，这个组只做匹配但不捕获结果，也不会分配组号）\n",
    "\n",
    "其实，在匹配时加 re.S 参数也可多行匹配："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' this is a \\n              multiline comment ']\n",
      "[' this is a \\n              multiline comment ']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('/\\*(.*?)\\*/', text2, re.S))\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.S)\n",
    "print(comment.findall(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "re.compile() 函数可以接受一个有用的标记 —— re.DOTALL。这使得正则表达式中的句点(.)可以匹配所有的字符，也包括换行符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a \\n              multiline comment ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 将 Unicode 文本统一表示为规范形式\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们正在同 Unicode 字符串打交道，但需要确保所有的字符串都拥有相同的底层表示\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "使用 unicodedata 模块下的 normalize() 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spicy Jalapeño\n",
      "Spicy Jalapeño\n",
      "False\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s1 == s2)\n",
    "print(len(s1))\n",
    "print(len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "'Spicy Jalape\\xf1o'\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "t1 = normalize('NFC', s1)\n",
    "t2 = normalize('NFC', s2)\n",
    "print(t1 == t2)\n",
    "print(ascii(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "'Spicy Jalapen\\u0303o'\n"
     ]
    }
   ],
   "source": [
    "t3 = normalize('NFD', s1)\n",
    "t4 = normalize('NFD', s2)\n",
    "print(t3 == t4)\n",
    "print(ascii(t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize() 的第一个参数制定了字符串应该如何完成规范表示。NFC表示字符应该是全组成的。NFD表示应该使用组合字符，每个字符应该是能完全分解开的。\n",
    "\n",
    "Python 还支持 NFKC 和 NFKD 的规范表示形式，它们为处理特定类型的字符增加了额外的兼容功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeno'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import combining\n",
    "t1 = normalize('NFD', s1)\n",
    "''.join(c for c in t1 if not combining(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "这个例子展示了 unicodedata 模块的另一个重要功能——用来检测字符是否属于某个字符类别。使用 combining() 函数可对字符做检查，判断它是否为一个组合型字符。这个模块中还有一些函数可用来查找字符类别、检测数字字符等\n",
    "\n",
    "**参考信息**：\n",
    "\n",
    "[http://www.unicode.org/faq/normalization.html](http://www.unicode.org/faq/normalization.html)\n",
    "\n",
    "[https://nedbatchelder.com/text/unipain.html](https://nedbatchelder.com/text/unipain.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 用正则表达式处理 Unicode 字符\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们正在用正则表达式处理文本，但是需要考虑处理 Unicode 字符\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "默认情况下 re 模块已经对某些 Unicode 字符类型有了基本的认识\n",
    "\n",
    "但是，要注意一些特殊情况。例如，当不区分大小写的匹配和大写转换匹配联合起来时，考虑会出现什么行为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='straße'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat = re.compile('stra\\u00dfe', re.IGNORECASE)\n",
    "s = 'straße'\n",
    "pat.match(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.match(s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STRASSE'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "把 Unicode 和正则表达式混在一起使用绝对是个能让人头痛欲裂的办法。如果真的要这么做，应该考虑安装第三方的正则表达式库（[https://pypi.org/project/regex/](https://pypi.org/project/regex/)）， 这些第三方库针对 Unicode 大写转换提供了完整的支持，还包含其他各种有趣的特性，包括近似匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 从字符串中去掉不需要的字符\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想在字符串的开始、结尾或中间去掉不需要的字符，比如说空格符\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "strip() 方法可用来从字符串的开始和结尾处去掉字符。lstrip() 和 rstrip() 可分别从左或从右侧开始执行去除字符的操作。默认情况下这些方法去除的是空格符，但也可以指定其他的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip:  hello world\n",
      "lstrip:  hello world \n",
      "\n",
      "rstrip:     hello world\n"
     ]
    }
   ],
   "source": [
    "s = '   hello world \\n'\n",
    "print('strip: ', s.strip())\n",
    "print('lstrip: ', s.lstrip())\n",
    "print('rstrip: ', s.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello=====\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "t = '-----hello====='\n",
    "print(t.lstrip('-'))\n",
    "print(t.strip('-='))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "去除字符的操作并不会对位于字符串中间的任何文本起作用。\n",
    "\n",
    "如果要对里面的空格执行某些操作，应该使用其他技巧，比如 replace() 方法或正则表达式替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello     world'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '  hello     world    \\n'\n",
    "s = s.strip()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(s.replace(' ', ''))\n",
    "print(re.sub('\\s+', ' ', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App store / Apple ID\n",
      "PayPal\n",
      "google\n",
      "instagram\n",
      "微信\n",
      "支付宝\n",
      "qq\n",
      "知乎\n",
      "百度/百度网盘\n",
      "淘宝\n",
      "京东\n",
      "苏宁\n",
      "微博\n",
      "领英\n",
      "钉钉\n",
      "腾讯云\n",
      "阿里云\n",
      "dnspod.cn\n",
      "知识星球\n",
      "百度网盘\n",
      "百度糯米\n",
      "银行卡\n",
      "饿了么\n",
      "美团外卖\n",
      "滴滴出行\n",
      "飞猪\n",
      "虎扑\n",
      "摩拜单车\n",
      "西电教务处\n",
      "bilibili      # 很重要\n",
      "简书\n",
      "36氪\n",
      "网易云音乐\n",
      "各种邮箱(网易、腾讯、谷歌)\n",
      "12306火车票订购官网\n",
      "万方账号 --> 绑在微信上\n",
      "交管12123\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\Ph\\Desktop\\log\\手机号解绑.txt') as f:\n",
    "    lines = (line.strip() for line in f)\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12 文本过滤和清理\n",
    "\n",
    "### 问题\n",
    "\n",
    "某些无聊的脚本小子在 Web 页面表单中填入了 'p̃ỹt̃h̃õñ' 这样的文本，我们想以某种方式将其清理掉\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "文本过滤和清理所涵盖的范围非常广泛，设计文本解析和数据处理方面的问题。在非常简单的层次上，我们可能会用基本的字符串函数 (例如 str.upper() 和 str.lower() ) 将文本转换为标准形式。简单的替换操作可通过 str.replace() 或 re.sub() 来完成，它们把重点放在移除或修改特定的字符序列上。也可以利用 unicodedata.normalize() 来规范化文本，如 2.9 节所示。\n",
    "\n",
    "然而我们可能想更进一步，比方说想清除整个范围内的字符，或者去除音符标志。要完成这些任务，可以使用常被忽视的 str.translate() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyth̃on\\x0cis\\tawesome\\r\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'pyth̃on\\fis\\tawesome\\r\\n'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步清理空格。要做到这步，先建立一个小型的转换表，然后使用 translate() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyth̃on is awesome\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remap = {\n",
    "    ord('\\t'): ' ',\n",
    "    ord('\\f'): ' ',\n",
    "    ord('\\r'): None\n",
    "}\n",
    "a = s.translate(remap)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以利用这种重新映射的思想进一步构建出更加庞大的转换表。例如，我们把所有的 Unicode 组和字符都去掉："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyth̃on is awesome\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) if unicodedata.combining(chr(c)))\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.translate(cmb_chrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里例子中，我们使用 dict.fromkeys() 方法构建了一个将每个 Unicode 组合字符都映射为 None 的字典\n",
    "\n",
    "原始输入会通过 unicodedata.normalize() 方法转换为分离形式，然后再通过 translate() 方法删除所有的重音符号\n",
    "\n",
    "下面看另一个例子。这里有一张转换表将所有的 Unicode 十进制数字字符映射为它们对应的 ASCII 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitmap = { c: ord('0') + unicodedata.digit(chr(c)) for c in range(sys.maxunicode) if unicodedata.category(chr(c)) == 'Nd'}\n",
    "len(digitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '\\u0661\\u0662\\u0663'\n",
    "x.translate(digitmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种用来清理文本的技术涉及 I/O 解码和编码函数。大致思路是首先对文本做初步的清理，然后通过结合 encode() 和 decode() 操作来修改或清理文本\n",
    "\n",
    "下面的例子先对原始文本做分解操作。后续的 ASCII 解码/编码只是简单地一次性丢弃所有不需要的字符。只有当最终目标是 ASCII 形式的文本时才有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyth̃on is awesome\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = unicodedata.normalize('NFD', a)\n",
    "b.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "文本过滤和清理的一个主要问题就是运行时的性能。一般来说操作越简单，运行得就越快。对于简单的替换操作，用 str.replace() 通常是最快的方式——即使必须多次调用它也是如此。比方说如果要清理掉空格符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " py\tt\f",
      "h\r",
      "on   \n",
      " python   \n"
     ]
    }
   ],
   "source": [
    "def clean_spaces(s):\n",
    "    s = s.replace('\\r', '').replace('\\t', '').replace('\\f', '')\n",
    "    return s\n",
    "s = ' py\\tt\\fh\\ron   '\n",
    "print(s)\n",
    "print(clean_spaces(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果试着调用它，就会发现这比使用 translate() 或者正则表达式的方法要快得多。\n",
    "\n",
    "另一方面，如果需要任何高级的操作，比如字符到字符的重映射或删除，那么 translate() 方法还是非常快的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13 对齐文本字符串\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们需要以某种对齐方式将文本做格式化处理\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "对于基本的字符串对齐要求，可以使用字符串的 ljust()、rjust() 和 center() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World         '"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello World'\n",
    "text.ljust(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Hello World'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.rjust(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Hello World     '"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.center(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World========='"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.ljust(20, '=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*********Hello World'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.rjust(20, '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'____Hello World_____'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.center(20, '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format()函数也可以用来轻松完成对齐的任务。需要做的就是合理利用'<'、'>'，或'^'字符以及一个期望的宽度值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Hello World'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '>20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World         '"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '<20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    Hello World     '"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '^20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'=========Hello World'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '=>20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World*********'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '*<20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'____Hello World_____'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text, '_^20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     Hello      World'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:>10} {:>10}'.format('Hello', 'World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format() 的好处之一是它并不是特定于字符串的。它能作用于任何值，这使得它更加通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    1.2345'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1.2345\n",
    "format(x, '>10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   1.23   '"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(x, '^10.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "在比较老的代码中，通常会发现 % 操作符用来格式化文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World         '"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%-20s' % text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Hello World'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%20s' % text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是在新的代码中，我们应该会更钟情于使用format()函数或方法。format()比 % 操作符提供的功能要强大多了。此外，format()可作用于任何类型的对象，比字符串的 ljust()、rjust() 以及 center() 方法要更加通用。\n",
    "\n",
    "format()函数的Python在线手册：[https://docs.python.org/3/library/string.html#formatspec](https://docs.python.org/3/library/string.html#formatspec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.14 字符串拼接及合并\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想将许多小字符串合并成一个大的字符串\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "如果想要合并的字符串在一个序列或可迭代对象中，那么将它们合并起来的最快方法就是使用join()方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Chicago Not Chicago?\n",
      "Is,Chicago,Not,Chicago?\n",
      "IsChicagoNotChicago?\n"
     ]
    }
   ],
   "source": [
    "pars = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
    "print(' '.join(pars))\n",
    "print(','.join(pars))\n",
    "print(''.join(pars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果只是想连接一些字符串，一般使用 + 操作符就足够完成任务了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Chicago Not Chicago?'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Is Chicago'\n",
    "b = 'Not Chicago?'\n",
    "a + ' ' + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果打算在源代码中将字符串字面值合并在一起，可以简单地将它们排列在一起，中间不加 + 操作符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HelloWorld'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Hello' 'World'\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "使用 + 操作符做大量的字符串拼接是非常低效的，最好先收集所有要连接的部分，最后再一次通过 join() 将它们连接起来\n",
    "\n",
    "一个相关的技巧（很漂亮的技巧）是利用生成器表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME,50,91.1'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['ACME', 50, 91.1]\n",
    "','.join(str(d) for d in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Amoy : Not Amoy? : Must Amoy\n",
      "Is Amoy : Not Amoy? : Must Amoy\n",
      "Is Amoy : Not Amoy? : Must Amoy\n"
     ]
    }
   ],
   "source": [
    "a = 'Is Amoy'\n",
    "b = 'Not Amoy?'\n",
    "c = 'Must Amoy'\n",
    "print(a + ' : ' + b + ' : ' + c)  # Ugly\n",
    "print(' : '.join([a, b, c]))      # Still Ugly\n",
    "print(a,b,c, sep=' : ')           # Better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们编写的代码要从许多短字符串中构建输出，则应该考虑编写生成器函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Amoy Not Amoy?\n"
     ]
    }
   ],
   "source": [
    "def sample():\n",
    "    s = 'Is Amoy Not Amoy?'.split()\n",
    "    for i in s:\n",
    "        yield i\n",
    "text = ' '.join(sample())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将这些片段重定向到 I/O："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for part in sample():\n",
    "    f.write(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "又或者我们能以混合的方式将 I/O 操作智能化地结合在一起："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def combine(source, maxsize):\n",
    "    parts = []\n",
    "    size = 0\n",
    "    for part in source:\n",
    "        parts.append(part)\n",
    "        size += len(part)\n",
    "        if size >= maxsize:\n",
    "            yield ''.join(parts)\n",
    "            parts = []\n",
    "            size = 0\n",
    "    yield ''.join(parts)\n",
    "    \n",
    "for part in combine(sample(), 32768):\n",
    "    f.write(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.15 给字符串中的变量名做插值处理\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想创建一个字符串，其中嵌入的变量名称会以变量的字符串值形式替换掉\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "Python 并不直接支持在字符串中对变量做简单的值替换。但是，这个功能可以通过字符串的 format() 方法近似模拟出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amoy has 37 messages.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{name} has {n} messages.'\n",
    "s.format(name='Amoy', n=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要被替换的值确实能在变量中找到，则可以将 format_map() 和 vars() 联合起来使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amoy has 37 messages.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Amoy'\n",
    "n = 37\n",
    "s.format_map(vars())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python3.6 版本开始，有了一个更优雅的解决方案： f-string\n",
    "\n",
    "并且 f-string 也可以自定义格式：对齐、宽度、符号、补零、精度、进制等  \n",
    "参考博客：[https://blog.csdn.net/sunxb10/article/details/81036693](https://blog.csdn.net/sunxb10/article/details/81036693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amoy has 37 messages.'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{name} has {n} messages.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amoy has 37 messages.'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F'{name} has {n} messages.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{7 * 3 + 4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amoy has 37 messages.'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{name.lower()} has {n} messages.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三种变量名插值处理的效率测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 ns ± 1.88 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit '%s has %s messages.' %(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 ns ± 2.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit '{name} has {n} message.'.format(name=name, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486 ns ± 1.34 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit '{} has {} message'.format(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 ns ± 0.879 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit f'{name} has {n} message.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见 f-string 的语法是**效率最高**的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.16 以固定的列数重新格式化文本\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们有一些很长的字符串，想将它们重新格式化，使得它们能按照用户指定的列数来显示\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "可以用 textwrap 模块来重新格式化文本的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotly's Python graphing library makes interactive,      publication-quality graphs online.\n",
      "Tutorials and tips about fundamental features of Plotly's python API. \n",
      "\n",
      "Plotly's Python graphing library makes\n",
      "interactive,      publication-quality graphs\n",
      "online.      Tutorials and tips about\n",
      "fundamental features of Plotly's python API. \n",
      "\n",
      "    Plotly's Python graphing library makes\n",
      "interactive,      publication-quality graphs\n",
      "online.      Tutorials and tips about\n",
      "fundamental features of Plotly's python API. \n",
      "\n",
      "Plotly's Python graphing library makes\n",
      "    interactive,      publication-quality graphs\n",
      "    online.      Tutorials and tips about\n",
      "    fundamental features of Plotly's python API.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "s = \"Plotly's Python graphing library makes interactive, \\\n",
    "     publication-quality graphs online. \\\n",
    "     Tutorials and tips about fundamental features of Plotly's python API.\"\n",
    "print(textwrap.fill(s, 105), '\\n')\n",
    "print(textwrap.fill(s, 48), '\\n')\n",
    "print(textwrap.fill(s, 48, initial_indent='    '), '\\n')\n",
    "print(textwrap.fill(s, 48, subsequent_indent='    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "textwrap 模块能够以简单直接的方式对文本格式做整理使其适合打印——尤其是当希望输出结果能很好地显示在终端上时。关于终端的尺寸大小，可以通过 os.get_terminal_size() 来获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.get_terminal_size().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.17 在文本中处理 HTML 和 XML 实体\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想将 &entity 或 &#code 这样的 HTML 或 XML 实体替换为它们相对应的文本。或者，我们需要生成文本，但是要对特定的字符（比如<,>或&）做转义处理\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "如果要生成文本，使用 html.escape() 函数来完成替换 <or\\> 这样的特殊字符相对来说是比较容易的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as \"<tag>text</tag>\".\n"
     ]
    }
   ],
   "source": [
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "import html\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n"
     ]
    }
   ],
   "source": [
    "print(html.escape(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    }
   ],
   "source": [
    "# Disable escaping of quotes\n",
    "print(html.escape(s, quote=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成 ASCII 文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Spicy Jalapen&#771;o'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Spicy Jalapeño'\n",
    "s.encode('ascii', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果由于某种原因在得到的文本中带有一些实体，而我们想手工将它们替换掉，通常可以利用各种 HTML 或 XML 解析器自带的功能函数和方法来完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy \"Jalapeño\".'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "html.unescape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prompt is >>>'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import unescape\n",
    "t = 'The prompt is &gt;&gt;&gt;'\n",
    "unescape(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "在生成 HTML 或 XML 文档时，适当地对特殊字符做转义处理常常是个容易被忽视的细节。尤其是当自己用 print() 或其他一些基本的字符串格式化函数来产生这类输出时更是如此。简单的解决方案是使用像 html.escape() 这样的工具函数\n",
    "\n",
    "如果需要反过来处理文本（即，将 HTML 或 XML 实体转换成对应的字符），有许多像 xml.sax.saxutils.unescape() | html.unescape() 这样的工具函数能帮上忙。\n",
    "\n",
    "如果是处理 HTML 或 XML，像 html.parser | xml.etree.ElementTree | lxml.etree.HTML 这样的解析模块应该已经解决了有关替换文本中实体的细节问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.18 文本分词\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们有一个字符串，想从左到右将它解析为标记流（ stream of tokens ）\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "利用模式对象的 scanner() 方法来完成分词操作。该方法会创建一个扫描对象，在给定的文本中重复调用 match() ，一次匹配一个模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='23')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='PLUS', value='+')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='42')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='TIMES', value='*')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='10')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import namedtuple\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "text = 'foo = 23 + 42 * 10'\n",
    "Token = namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "        \n",
    "for tok in generate_tokens(master_pat, text):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想以某种方式对标记流做过滤处理，可以用生成器表达式。比如过滤掉所有的空格标记："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='NUM', value='23')\n",
      "Token(type='PLUS', value='+')\n",
      "Token(type='NUM', value='42')\n",
      "Token(type='TIMES', value='*')\n",
      "Token(type='NUM', value='10')\n"
     ]
    }
   ],
   "source": [
    "tokens = (tok for tok in generate_tokens(master_pat, text) if tok.type != 'WS')\n",
    "for tok in tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "对于更加高级的文本解析，第一步往往是分词处理。这里推荐三个中文分词的包：\n",
    "\n",
    "1. 要“做最好的中文分词组件”的**结巴分词**。[https://github.com/fxsjy/jieba](https://github.com/fxsjy/jieba)\n",
    "2. 来自清华的**THULAC**。[https://github.com/thunlp/THULAC-Python](https://github.com/thunlp/THULAC-Python)\n",
    "3. 来自北大的**PKUSeg**。[https://github.com/lancopku/pkuseg-python](https://github.com/lancopku/pkuseg-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.19 编写一个简单的递归下降解析器\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们需要根据一组语法规则来解析文本，以此执行相应的操作或构建一个抽象语法树来表示输入\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "在这个问题中，我们把重点放在根据特定的语法来解析文本上。要做到这些，应该以 BNF 或 EBNF 的形式定义出语法的正是规格\n",
    "\n",
    "下面是构建一个递归下降的表达式计算器的Demo："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES, DIVIDE, LPAREN, RPAREN, WS]))\n",
    "\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n",
    "            \n",
    "# Parser\n",
    "class ExpressionEvaluator:\n",
    "    def parse(self, text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None    # Last symbol consumed\n",
    "        self.nexttok = None    # Next symbok tokenized\n",
    "        self._advance()    # Load first lookahead token\n",
    "        return self.expr()\n",
    "\n",
    "    def _advance(self):\n",
    "        'Advence one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "    \n",
    "    def _accept(self, toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def _expect(self, toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "            \n",
    "    # Grammar rules follow\n",
    "    \n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "        \n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "        \n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "    \n",
    "    def factor(self):\n",
    "        'factor ::= NUM | ( expr )'\n",
    "        \n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是以交互的方式使用 ExpressionEvaluator 类的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ExpressionEvaluator()\n",
    "e.parse('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + 3 * 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + (3 + 4) * 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('2 + 8 / 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Expected NUMBER or LPAREN (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3291\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-13-ab9f4012cc20>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    e.parse('2 + (3 + * 4)')\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m33\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    return self.expr()\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m60\u001b[0m, in \u001b[0;35mexpr\u001b[0m\n    right = self.term()\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m70\u001b[0m, in \u001b[0;35mterm\u001b[0m\n    termval = self.factor()\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m86\u001b[0m, in \u001b[0;35mfactor\u001b[0m\n    exprval = self.expr()\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m60\u001b[0m, in \u001b[0;35mexpr\u001b[0m\n    right = self.term()\n",
      "  File \u001b[0;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[0m, line \u001b[0;32m70\u001b[0m, in \u001b[0;35mterm\u001b[0m\n    termval = self.factor()\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-29a061f22aa4>\"\u001b[1;36m, line \u001b[1;32m90\u001b[1;36m, in \u001b[1;35mfactor\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise SyntaxError('Expected NUMBER or LPAREN')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Expected NUMBER or LPAREN\n"
     ]
    }
   ],
   "source": [
    "e.parse('2 + (3 + * 4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解析树Demo\n",
    "\n",
    "如果我们想做的不只是纯粹的计算，那就需要修改 ExpressionEvaluator 类来实现\n",
    "\n",
    "比如，下面的实现构建了一棵简单的解析树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionTreeBuilder(ExpressionEvaluator):\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }\"\n",
    "        \n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval = ('+', exprval, right)\n",
    "            elif op == 'MINUS':\n",
    "                exprval = ('-', exprval, right)\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }\"\n",
    "        \n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval = ('*', termval, right)\n",
    "            elif op == 'DIVIDE':\n",
    "                termval = ('/', termval, right)\n",
    "            return termval\n",
    "        \n",
    "    def factor(self):\n",
    "        'factor ::= NUM | ( expr )'\n",
    "        \n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPRREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+', None, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ExpressionTreeBuilder()\n",
    "\n",
    "# 这个小bug还没找出来\n",
    "e.parse('5 + 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('*', 5, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('5 * 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/', 6, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.parse('6 / 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.20 在字符串上执行文本操作\n",
    "\n",
    "### 问题\n",
    "\n",
    "我们想在字节串（ Byte String ）上执行常见的文本操作（例如，拆分、搜索和替换）\n",
    "\n",
    "### 解决方案\n",
    "\n",
    "字节串已经支持大多数和文本字符串一样的内建操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'Hello World'\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.startswith(b'Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Hello', b'World']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello Cruel World'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(b'Hello', b'Hello Cruel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以在字节串上执行正则表达式的模式匹配操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'FOO', b'BAR', b'SPAM']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "data = b'FOO:BAR,SPAM'\n",
    "re.split(b'[:,]', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讨论\n",
    "\n",
    "就绝大部分情况而言，几乎所有能在文本字符串上执行的操作同样也可以在字节串上进行。但是，还是有几个显著的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Hello World'  # Text string\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = b'Hello World'\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，在字节串上是没有普通字符串那样的格式化操作的。  \n",
    "如果想在字节串上做任何形式的格式化操作，应该使用普通的文本字符串然后再做编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ACME       100 490.10'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:7s}{:7d}{:7.2f}'.format('ACME', 100, 490.1).encode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，由于字节串和 Python 中许多其他部分并不能很好地相容，这样为了保证结果的正确性，我们只能手动去执行各种各样的编码/解码操作。  \n",
    "坦白地说，如果要同文本打交道，在程序中使用普通的文本字符串就好，不要用字节串。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
